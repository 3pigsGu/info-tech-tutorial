{"meta":{"title":"Infomatic Technique Tutorial","subtitle":"Jack Gu's personal tech-tutorial","description":"This is my personal blog to share latest techniques and theories in High-Tech field.","author":"Jack Gu","url":"https://3pigsgu.github.io/info-tech-tutorial","root":"/info-tech-tutorial/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2019-12-22T14:45:07.436Z","updated":"2019-12-22T14:45:07.436Z","comments":false,"path":"/404.html","permalink":"https://3pigsgu.github.io/info-tech-tutorial/404.html","excerpt":"","text":""},{"title":"关于","date":"2019-12-17T08:46:50.000Z","updated":"2019-12-18T10:02:03.930Z","comments":false,"path":"about/index.html","permalink":"https://3pigsgu.github.io/info-tech-tutorial/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-12-17T08:47:01.000Z","updated":"2019-12-18T06:04:12.808Z","comments":true,"path":"categories/index.html","permalink":"https://3pigsgu.github.io/info-tech-tutorial/categories/index.html","excerpt":"","text":""},{"title":"项目","date":"2019-12-17T08:47:46.000Z","updated":"2019-12-18T10:00:37.308Z","comments":false,"path":"repository/index.html","permalink":"https://3pigsgu.github.io/info-tech-tutorial/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-12-17T08:41:10.000Z","updated":"2019-12-18T05:12:16.375Z","comments":true,"path":"tags/index.html","permalink":"https://3pigsgu.github.io/info-tech-tutorial/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Apache Flink在Windows环境下部署与运行","slug":"flink/flink-tutorial-02","date":"2019-12-30T07:46:29.000Z","updated":"2019-12-30T07:51:51.251Z","comments":true,"path":"2019/12/30/flink/flink-tutorial-02/","link":"","permalink":"https://3pigsgu.github.io/info-tech-tutorial/2019/12/30/flink/flink-tutorial-02/","excerpt":"","text":"","categories":[{"name":"Flink实战","slug":"Flink-Action","permalink":"https://3pigsgu.github.io/info-tech-tutorial/categories/Flink-Action/"}],"tags":[{"name":"框架实战","slug":"Architecture-Action","permalink":"https://3pigsgu.github.io/info-tech-tutorial/tags/Architecture-Action/"}]},{"title":"Flink实战全集","slug":"flink/flink-tutorial-00","date":"2019-12-28T05:21:46.000Z","updated":"2019-12-28T14:23:00.191Z","comments":true,"path":"2019/12/28/flink/flink-tutorial-00/","link":"","permalink":"https://3pigsgu.github.io/info-tech-tutorial/2019/12/28/flink/flink-tutorial-00/","excerpt":"","text":"第一篇： Apache Flink快速入门","categories":[{"name":"Flink实战","slug":"Flink-Action","permalink":"https://3pigsgu.github.io/info-tech-tutorial/categories/Flink-Action/"}],"tags":[{"name":"框架实战","slug":"Architecture-Action","permalink":"https://3pigsgu.github.io/info-tech-tutorial/tags/Architecture-Action/"}]},{"title":"Apache Flink快速入门","slug":"flink-tutorial-01","date":"2019-12-27T18:09:52.000Z","updated":"2020-01-01T16:09:21.883Z","comments":true,"path":"2019/12/28/flink-tutorial-01/","link":"","permalink":"https://3pigsgu.github.io/info-tech-tutorial/2019/12/28/flink-tutorial-01/","excerpt":"","text":"本篇的目的是带Apache Flink初学者引入Flink的大门，并提供一个Word Count的示例来了解如何使用Flink框架，希望能给各位开发爱好者提供浅显易懂的理解。 1. Java运行环境Apache Flink是基于Java语言开发的，并且能运行在Windows, Linux和Mac OS操作系统上。为了能正常运行Flink, 唯一的前提条件是确保安装了Java 6或更高版本的版本，并且已设置JAVA_HOME环境变量。 2. Flink在Windows环境下运行如果要在Windows计算机上本地运行Flink，则需要下载Flink二进制发行版并解压缩。之后，您可以使用Windows批处理文件（.bat），也可以使用Cygwin运行Flink Jobmanager。 (Flink下载地址) 2.1. 以.bat文件启动要从Windows命令行启动Flink，请打开命令窗口，导航到Flink的bin/目录，然后运行start-cluster.bat。注意：Java运行时环境的bin文件夹必须包含在Window的％PATH％变量中。 123456$ cd flink$ cd bin$ start-cluster.batStarting a local cluster with one JobManager process and one TaskManager process.You can terminate the processes via CTRL-C in the spawned shell windows.Web interface by default on http://localhost:8081/. 然后，您需要打开另一个终端使用flink.bat运行作业。 2.2. 安装Cygwin以Unix脚本启动使用Cygwin，您需要启动Cygwin终端，导航到Flink目录并运行start-cluster.sh脚本： 123$ cd flink$ bin/start-cluster.shStarting cluster. 3. Flink在非Windows环境下运行 在此处下载最新的flink二进制文件, 可以选择任意的scala版本：例如Apache Flink 1.9.1 for Scala 2.12。如果您打算使用Hadoop，请选择hadoop相关构件版本。 解压文件压缩包并启动Flink：12tar xzvf flink-1.9.1-bin-scala_2.12.tar.gz #Unpack the downloaded archive./flink/bin/start-cluster.sh #Start Flink Flink已配置为在本地运行。要确保flink正在运行，您可以检查flink/log/中的日志，或打开在http：//localhost：8081上运行的flink jobManager的界面。 停止Flink：1./flink/bin/stop-cluster.sh 4. Flink开发环境要从您的IDE运行flink程序（我们可以使用Eclipse或Intellij IDEA（推荐）），您需要两个依赖项：flink-java/flink-scala和flink-clients（自2016年2月起）。可以使用Maven和SBT添加这些JARS（如果使用的是Scala）。这里我们只介绍如何使用Java进行获取依赖项，而且后面的代码也同样基于Java程序作为示例。核心的Maven依赖包括如下： 12345678910111213141516171819202122232425262728&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;&#x2F;project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;&#x2F;java.version&gt; &lt;flink.version&gt;1.9.1&lt;&#x2F;flink.version&gt; ...&lt;&#x2F;properties&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt; &lt;artifactId&gt;flink-java&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;flink.version&#125;&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt; &lt;artifactId&gt;flink-streaming-java_2.11&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;flink.version&#125;&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt; &lt;artifactId&gt;flink-clients_2.11&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;flink.version&#125;&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;&#x2F;groupId&gt; &lt;artifactId&gt;flink-connector-wikiedits_2.11&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;flink.version&#125;&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 5. Socket Window Word Count示例代码您可以在GitHub上找到此SocketWindowWordCount示例的完整Java版源代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import org.apache.flink.api.common.functions.FlatMapFunction;import org.apache.flink.api.common.functions.ReduceFunction;import org.apache.flink.api.java.utils.ParameterTool;import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.api.windowing.time.Time;import org.apache.flink.util.Collector;public class SocketWindowWordCount &#123; public static void main(String[] args) throws Exception &#123; // the port to connect to final int port; try &#123; final ParameterTool params = ParameterTool.fromArgs(args); port = params.getInt(\"port\"); &#125; catch (Exception e) &#123; System.err.println(\"No port specified. Please run 'SocketWindowWordCount --port &lt;port&gt;'\"); return; &#125; // get the execution environment final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // get input data by connecting to the socket DataStream&lt;String&gt; text = env.socketTextStream(\"localhost\", port, \"\\n\"); // parse the data, group it, window it, and aggregate the counts DataStream&lt;WordWithCount&gt; windowCounts = text .flatMap(new FlatMapFunction&lt;String, WordWithCount&gt;() &#123; @Override public void flatMap(String value, Collector&lt;WordWithCount&gt; out) &#123; for (String word : value.split(\"\\\\s\")) &#123; out.collect(new WordWithCount(word, 1L)); &#125; &#125; &#125;) .keyBy(\"word\") .timeWindow(Time.seconds(5), Time.seconds(1)) .reduce(new ReduceFunction&lt;WordWithCount&gt;() &#123; @Override public WordWithCount reduce(WordWithCount a, WordWithCount b) &#123; return new WordWithCount(a.word, a.count + b.count); &#125; &#125;); // print the results with a single thread, rather than in parallel windowCounts.print().setParallelism(1); env.execute(\"Socket Window WordCount\"); &#125; // Data type for words with count public static class WordWithCount &#123; public String word; public long count; public WordWithCount() &#123;&#125; public WordWithCount(String word, long count) &#123; this.word = word; this.count = count; &#125; @Override public String toString() &#123; return word + \" : \" + count; &#125; &#125;&#125; 更多参考：Flink官方示例代码 5. 运行Socket Window Word Count示例接下来，我们来运行演示名为SocketWindowWordCount的Flink应用示例。 首先，我们使用netcat在CMD命令窗口中通过以下方式启动本地服务：1$ nc -l -p 9000 然后，通过flink run命令提交Flink程序：12$ ./bin/flink run SocketWindowWordCount.jar --port 9000Starting execution of program 程序连接到socket套接字并等待输入。您可以检查Web界面以验证作业是否按预期运行： 接着我在CMD命令窗口输入下面数个单词：1234$ nc -l -p 9000lorem ipsumipsum ipsum ipsumbye 我们会在启动的Flink集群的任一个窗口看到如下输出：123lorem : 1bye : 1ipsum : 4 这里如果遇到应用程序报Flink Connection refused错误，请参考如下链接： connection failed when running flink in a cluster Unable to run flink example program,Connection refused Flink Connection refused: localhost/127.0.0.1:8081 参考文献： Apache Flink Documentation; Getting Started with Apache-Flink.","categories":[{"name":"Flink实战","slug":"Flink-Action","permalink":"https://3pigsgu.github.io/info-tech-tutorial/categories/Flink-Action/"}],"tags":[{"name":"框架实战","slug":"Architecture-Action","permalink":"https://3pigsgu.github.io/info-tech-tutorial/tags/Architecture-Action/"}]},{"title":"Tensorflow安装详解与样例Demo演示","slug":"tensorflow/tensorflow-tutorial-01","date":"2019-12-26T03:40:37.000Z","updated":"2019-12-28T13:55:48.111Z","comments":true,"path":"2019/12/26/tensorflow/tensorflow-tutorial-01/","link":"","permalink":"https://3pigsgu.github.io/info-tech-tutorial/2019/12/26/tensorflow/tensorflow-tutorial-01/","excerpt":"","text":"在使用Tensorflow进行机器学习之前， 我们需要在自己的机器上先安装相关的软件。我们可以安照Tensorflow官方网站上提供的步骤，一步一步的进行安装。官网上会提供多种环境下的部署方法，包括：Linux， Windows，MacOS和Docker容器等等。一般建议在容器或者Virtualenv这样的虚拟环境下进行Tensorflow的安装以及与此配套的一些第三方软件的集成。比较好的一种方式是对于生产环境可以采用Docker这类的容器进行Tensorflow的部署，而对于开发环境可以采用Conda的依赖环境进行安装。 这样可以保证不同版本之间的强依赖关系，避免依赖导致的不必要的冲突发生。 这篇文章将一步一步的带大家在Conda的依赖环境下安装Tensorflow和其周边的第三方插件， 并且演示一个使用Tensorflow的小示例。接下来，我在Windows设备上操作整个过程。 1. Minconda安装Minconda和Conda的区别在于Minconda其实就是Conda的一个子集，是Conda的一个简化安装版： 如果您选择Anaconda，可能：是conda或Python的新手，喜欢一次性安装Python和150多个科学软件包。有时间和磁盘空间-可能需要几分钟和300MB的磁盘空间。不想单独安装要使用的每个软件包。 如果您选择Miniconda，可能：不介意安装要单独使用的每个软件包。没有时间或磁盘空间来一次安装150个以上的软件包。希望快速访问Python和conda命令，并且希望以后再整理其他程序。 这里提供Miniconda安装软件的下载地址, 请依据自己的喜好和机器环境酌情选择。如果你下直接安装完整的Conda软件，也可以在这个链接下载。详细的操作文档请参见：Conda文档。 1.1. 管理Conda 通查看Conda的版本验证Conda是否安装： 1C:\\Users\\44355&gt; conda --version 或者 1C:\\Users\\44355&gt; conda -V Conda会返回版本号，例如：conda 4.8.0。 查看更详细的Conda信息： 1C:\\Users\\44355&gt; conda info Conda返回更多的安装信息，包括安装路径、Conda版本、Python版本、基础环境路径、包缓存路径等。 123456789101112131415161718192021222324252627 active environment : base active env location : D:\\software\\Miniconda3 shell level : 1 user config file : C:\\Users\\44355\\.condarcpopulated config files : C:\\Users\\44355\\.condarc conda version : 4.8.0 conda-build version : not installed python version : 3.7.3.final.0 virtual packages : base environment : D:\\software\\Miniconda3 (writable) channel URLs : https://repo.anaconda.com/pkgs/main/win-64 https://repo.anaconda.com/pkgs/main/noarch https://repo.anaconda.com/pkgs/r/win-64 https://repo.anaconda.com/pkgs/r/noarch https://repo.anaconda.com/pkgs/msys2/win-64 https://repo.anaconda.com/pkgs/msys2/noarch package cache : D:\\software\\Miniconda3\\pkgs C:\\Users\\44355\\.conda\\pkgs C:\\Users\\44355\\AppData\\Local\\conda\\conda\\pkgs envs directories : D:\\software\\Miniconda3\\envs C:\\Users\\44355\\.conda\\envs C:\\Users\\44355\\AppData\\Local\\conda\\conda\\envs platform : win-64 user-agent : conda/4.8.0 requests/2.22.0 CPython/3.7.3 Windows/10 Windows/10.0.17763 administrator : False netrc file : None offline mode : False 更新Conda到最新版本： 1C:\\Users\\44355&gt; conda update conda 更多参考：Conda Management 1.2. Conda的环境管理 命令行创建一个新环境 1C:\\Users\\44355&gt; conda create --name tensorflow-env 命令行激活指定环境 1C:\\Users\\44355&gt; conda activate tensorflow-env 激活环境后所有的操作会在当前激活的环境下进行。 命令行停用当前环境 1(tensorflow-env) C:\\Users\\44355&gt; conda deactivate 更多参考：Conda Environment Management 2. 在tensorflow-env环境下进行Python安装 当我们在Conda中激活tensorflow-env环境，则出现如下提示：1(tensorflow-env) C:\\Users\\44355&gt; 此时表明当前已经进入tensorflow-env环境。 由于在安装Conda的时候其自身内嵌安装了相应的Python版本，因此我们无需再额外安装Python,就可以直接在tensorflow-env环境中安装Tensorflow。首先查看Tensorflow各个版本：1(tensorflow-env) C:\\Users\\44355&gt; conda search tensorflow 或者1(tensorflow-env) C:\\Users\\44355&gt; conda search tensorflow-gpu 选择一个安装版本进行安装：1(tensorflow-env) C:\\Users\\44355&gt; conda install tensorflow=1.8.0 或者直接安装最新版本的Tensorflow：1(tensorflow-env) C:\\Users\\44355&gt; conda install tensorflow 安装完成后验证Tensorflow是否安装成功：1234(tensorflow-env) C:\\Users\\44355&gt; python&gt;&gt;&gt; import tensorflow as tf #不报错即安装成功&gt;&gt;&gt; exit()(tensorflow-env) C:\\Users\\44355&gt; conda deactivate 更多参考：Tensorflow官方安装 3. 在tensorflow-env环境下安装常用的第三方软件3.1. 安装Jupyter Jupyter是一款为了开发跨多种编程语言的交互式计算的开源软件，它提供开放的标准和服务。JupyterLab是用于Jupyter笔记本，代码和数据的基于Web的交互式开发环境。 JupyterLab非常灵活：配置和安排用户界面以支持数据科学，科学计算和机器学习中的各种工作流程。 JupyterLab是可扩展的和模块化的：编写可添加新组件并与现有组件集成的插件。接下来我们通过pip命令来安装JupyterLab。 1(tensorflow-env) C:\\Users\\44355&gt; pip install jupyterlab 更多参考：Jupyter官方安装 Jupyter Notebook是Jupyter中的一个开源Web应用程序，允许您创建和共享包含实时代码，方程式，可视化效果和叙述文本的文档。用途包括：数据清理和转换，数值模拟，统计建模，数据可视化，机器学习等。我们可以通过命令来启动Jupyter Notebook服务。 1(tensorflow-env) C:\\Users\\44355&gt; jupyter notebook 终端上会打印如下启动信息： 123456789101112[I 10:20:26.155 NotebookApp] Serving notebooks from local directory: C:\\Users\\44355[I 10:20:26.160 NotebookApp] The Jupyter Notebook is running at:[I 10:20:26.161 NotebookApp] http://localhost:8888/?token=00f06b6e31b020740277e2d20eef416da634cc55d6f6a2ba[I 10:20:26.162 NotebookApp] or http://127.0.0.1:8888/?token=00f06b6e31b020740277e2d20eef416da634cc55d6f6a2ba[I 10:20:26.162 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[C 10:20:26.406 NotebookApp] To access the notebook, open this file in a browser: file:///C:/Users/44355/AppData/Roaming/jupyter/runtime/nbserver-138920-open.html Or copy and paste one of these URLs: http://localhost:8888/?token=00f06b6e31b020740277e2d20eef416da634cc55d6f6a2ba or http://127.0.0.1:8888/?token=00f06b6e31b020740277e2d20eef416da634cc55d6f6a2ba 接下来会自动打开浏览器进入Jupyter Notebook操作界面： 更多参考：Jupyter官方文档 3.2. 安装MatplotlibMatplotlib是一个Python 2D绘图库，它以多种硬拷贝格式和跨平台的交互式环境生成出版物质量的图形。 Matplotlib可用于Python脚本，Python和IPython Shell，Jupyter Notebook，Web应用程序服务器和四个图形用户界面工具包。接下来我们通过Python来安装Matplotlib插件： 12(tensorflow-env) C:\\Users\\44355&gt; python -m pip install -U pip(tensorflow-env) C:\\Users\\44355&gt; python -m pip install -U matplotlib 更多参考：Matplotlib官方安装现在我们只需几行代码就可以生成图表，直方图，功率谱，条形图，误差图，散点图等。 4. 示例代码演示TensorFlow, Jupyter Notebook, and Matplotlib的使用接下来，我们在Jupyter Notebook界面中写一段很简单的演示代码。首先我们在Jupyter Notebook操作界面的右上角单击 new 按钮，然后选择Python版本，这边选择的是安装Conda时自带的Python3. 进入代码操作界面后，可以把默认代码文件名Untitled修改成自己定义的名字，这里修改成“My First Notebook”。 然后我们在代码块区域输入如下示例代码： 1234567891011import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt%matplotlib inlinea = tf.random_normal([2,20])sess = tf.Session()out = sess.run(a)x, y = outplt.scatter(x, y)plt.show() 代码中tf.random_normal()函数用于从服从指定正太分布的数值中取出指定个数的值。 shape=[2,20]是输出张量的形状，一个2行20列的矩阵。然后tensorflow运行计算后的输出按行分别传给x和y两个变量。最后以Matplotlib的scatter散点图的方式图形化展示，其中x代表横轴值，y代表纵轴值。代码可以分成多个代码块，代码块可以通过左上角 + 号增加，最终完成界面如下： 完成Python示例代码后，可以点击 Run 按钮逐步执行代码块，这里代码调用tensorflow正太分布算法，最终结果会使用Matplotlib去直观的展示20个点的随机正太分布情况。 4. 结语至此整个Tensorflow的安装详解和示例代码演示到此结束，如果需要了解更多的相关细节，请阅读本文中提供的更多的官方链接。如有疑问欢迎大家留言！欢迎来踩留印！","categories":[{"name":"Tensorflow实战","slug":"Tensorflow-Action","permalink":"https://3pigsgu.github.io/info-tech-tutorial/categories/Tensorflow-Action/"}],"tags":[{"name":"框架实战","slug":"Architecture-Action","permalink":"https://3pigsgu.github.io/info-tech-tutorial/tags/Architecture-Action/"}]}]}